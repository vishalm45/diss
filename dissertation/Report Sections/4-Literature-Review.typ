#import "../template/layout-template.typ" as layout
#show: doc => layout.MainPageSettings(doc)

= Literature Review
== Overcoming Choice Overload

There have been multiple theories on combatting this problem. In terms of entertainment, recognising popular genres and user preferences is vital to providing a tailored experience without any overwhelming emotion.

The first method is to have a sequential choice architecture, where users are presented with subsets of options in multiple rounds, retaining one from each round until the final choice is made @besedes_reducing_nodate. This architecture was found to be the most effective in improving the decision making quality, by reducing cognitive load. It also reduced bias by deffering the final choice until all the options were considered. This method does not utilise machine learning, but instead focuses on the user making choices through a case of "rounds" until the final choice is made. While this method may be effective, it can be time-consuming, with users being demotivated to process through many films to reach a final decision. 

Another way to combat this is to implement a deep-learning based model that captures user-specific context to tailer recommendations directly @zhou_spoiled_2020. This model learns from the user and then based on that, returns appropriate recommednations. However, it is also important to note that user preferences are not static, and can change over time. As such, recommendations that utilise a "first learn, then earn" approach may beocme less effective over time. 

== Machine Learning
Machine learning is on the rise in applications, with the ability to learn from data and implement improvements automatically, improving efficiency and effectiveness of applications. Integrating machine learning into an application can provide many benefits when it comes to the user experience. 

=== Machine learning and user experience
Machine learning in applications can offer an increased personalisation and customisation of the user experience, by learning from user preferences and environmental factors @carmona_relationship_2018. 

When it comes to developing an application with machine learning, there are two fundamental roles of UX (user experience) in ML systems: Problem setting and Problem solving. Problem setting is the process of identifying the right ML application by focussing on user-centered problems, and problem solving is the process of designing ML systems that produce outputs that align with the user needs @yang_role_nodate. Problem solving is the most important, as this will need to be tailored to the user, and in my case output recommendations, otherwise this will be unsatisfactory. Developing an application combining both user experience and machine learning is complex, and there are some challenges to consider, such as the mismatch between the goals of both. Machine learning improves the experience of users through the use of data and algorithms, whereas UX focusses on the contextual relevance. It is also important that users trust the outputs from ML, and having strategies to handle ML errors can help with this. 

Alongside the trust of applications, it is important to consider the privacy concerns which ties into the experience and satisfaction of the user, as any confusion with how their data is processed will negatively affect experience. If malicious users were able to recover the data used by these models, they could infer sensitive information about the user, which could be a serious issue @cristofaro_overview_2020.

=== Machine Learning in a Mobile Application
Mobile applications are already a staple in lifestyles, users can access information quickly and easily, as applications are constantly optimised to be lightweight and efficient to run using a cellular data connection and limited power. This is currently a problem when it comes to machine learning, as this is a resource intensive process if you were to run all programs and processes locally on the device. ChatGPT uses a server-based model called server-sent events (SSE). This allows the model to be run on a server, and the mobile application sends requests to the server, which then returns the response. This is a more efficient way to run machine learning models on mobile devices, as it reduces the amount of processing power needed on the device itself @gitonga_real-time_2024. This is just one of the options that this can allow for efficient machine learning, while maintaining resources.

Another way to having a positive machine learning experience is to utilise TinyML, a paradigm of running machine learning on embedded edge devices with limited computational, memory and power resources @ray_review_2022. The goal of TinyML is to minimise energy consumption, optimise memory usage and achieve acceptable accuracy. This is beneficial for my project, as this will be a mobile application that utilises machine learning. This will allow for the application to run efficiently on the device, without using too much power or memory, and also be beneficial in terms of privacy, as the data will be processed locally on the user's device, as opposed to sending sensitive information to a server. TinyML is scalable as well, as it has the ability to function without constant internet connectivity @schizas_tinyml_2022. 

Machine learning is constantly evolving, and TinyML will be cructial to next technologies. For instance, many of the crucial parts of augmented reality glasses are constantly active and powered by batteries. Such devices will benefit greatly from developments in TinyML. 

== Data preprocessing in mobile applications
Preprocessing plays a critical role in improving model performance on devices, espeically those with limited computation power, and memory @haseeb_optimizing_2024. Studies using K-Nearest Neighbours, Support Vector Machines (SVM) and other machine learning algorithms combined with various preprocessing techniques have shown that model performance improves with preprocessing, and time taken is reduces as a result, which is beneficial for power restricted devices and situations.

There are many data preprocessing techniques that I can utilise for my model that will improve performance and result in a high accuracy and execute in little time. A combination of techniques to consider is Random Forest, utilised with Boruta-selected features. This combination on the CICIDS2017 dataset resulted in an accuracy value of 99.99% @mishra_lirad_2025. 

== Deep learning VS Traditional Machine Learning
Deep learning is a subset of machine learning that uses multi-layered neural networks to automatically learn features from data. Unlike traditional machine learning algorithms, which require manual feature engineering, deep learning models can autonomously extract and transform features from raw data, making them effective for unstructured data @taye_understanding_2023.

Traditional machine learning approaches, including algorithms like Support Vector Machines (SVM) rely on predefined features and are generally more computationally efficient. However, they may struggle with capturing complex patterns in data, such as emotions regarding movies, especially when dealing with large-scale datasets like the movie databases used in this project. 

In a comparative study, traditional machine learning algorithms were evaluated against a Convolutional Neural Network (CNN) for text classification tasks @kamath_comparative_2018. The study utilised two datasets: a proprietary health insurance dataset and the publicly available Tobaccy-3482 dataset. Traditional ML models, including Logistic Regression, SVM, Naive Bayes and Random Forest, were implemented using bag-of-words representations. In contrast, the CNN model employed word embeddings and convolutional layers to capture semantic relationships in the text. 

The findings revealed that the CNN outperformed traditional ML models across both datasets. Specifically, the CNN achieved an accuracy of 96% on the processed Tobacco dataset and 89.27% on the processed Health dataset. In comparison, the best-performing traditional model, Logistic Regression, achieved 81% and 77% accuracy respectively. 

Despite these advantages however, deep learning models require substantial computational resources, longer training times and careful tuning of hyperparameters. While traditional machine learning mdoels offer simplicity and efficiency, deep learning approaches provide superior performance in handling compelx and unstructured data. The drawbacks that deep learning models have can be offset through the use of TinyML, which allows for the deployment of deep learning models using lightweight modifications. This results in an effective model that is also efficient to be run on devices with resource constraints.

== Natural Language Processing (NLP) 
Natural Language Processing (NLP) is a field of artificial intelligence concerned with the interaction between computers and human language. It focusses on enabling machines to understand, interpret and generate natural language text or speech in a meaningful way. 

In recent years, the development of deep learning models has drastically improved the performance of NLP systems. One of these is BERT (Bidirectional Encoder Representations from Transformers) @gardazi_bert_2025. BERT is a pre-trained transformer model that learns contextual representations of word by processing text bidirectionally @devlin_bert_2019. Unlike earlier models that read text in a single direction (left-to-right or right-to-left), BERT's ability to consider the context from both directions has proven highly effective in a variety of language understanding tasks, such as sentiment analysis and question answering. 

However, BERT's large size and high computational demands can be impractical for many real-world applications, especially when considering the project aim to have a machine learning chatbot system on a mobile device, which has limited resources. To address this, there are optimised variants of BERT, such as DistilBERT @sanh_distilbert_2020, which retains around 97% of BERT's performance while reducing the model size by 40% and increasing inference speed by 60%. This balance of performance and efficiency makes DistilBERT a compelling option for deployment in resource-constrained environments. 

The integration of BERT and its lightweight variants such as DistilBERT into mobile applications represent a major advancement over traditional models. This not only allows for more accurate and context-aware recommendations, but also sentiment analysis, which can be used to gauge user preferences and improve user experience. 

== Cross-Platform Development and Use of Expo
Cross-platform development has emerged as a compelling solution to the challenges posed by native mobile app development. Traditional native applications require separate implementations for each target platform - commonly iOS and Android - which leads to increased development time, higher maintenance consts, and platform-specific expertise. In contrast, cross-platform frameworks allow developers to write a single codebase that runs across multiple platforms, streamlining the development lifecycle. For a project being developed by a single person, this approach is particularly advantageous.

In a study, four major cross-platform development models were identified: web, hybrid, interpreted and generated apps @xanthopoulos_comparative_2013. Using frameworks such as Expo @noauthor_expo_nodate aligns with the hybrid approach, where applications are primarlily written using widespread web technologies such as JavaScript, HTML5 and CSS. These apps are wrapped in a native container that provides access to device APIs, simulating a native experience. One of the key benefits of hybrid apps is their ability to leverage a single technology stack - namely JavaScript - to develop applications that are deployable through official app stores like Google Play and Apple App Store. This enables easier onboarding for developers who are already familiar with web technologies.

However, this comes with its limitations. The performance of hybrid applications is generally lower compared to that of fully native apps, especially when handling complex animations or resource-intensive operations. While frameworks like Expo offer access to a broad set of native features through JavaScript APIs, there can still be constraints. For example, if a specific device API is not yet supported by the framework, developers must either wait for community or official support or eject from the managed workflow to write native code manually. There are also potential issues with app store compliance. Applications that do not adhere to the guidelines of the respective app stores may face rejection, particularly by Apple's App Store, which maintains strict guidelines on user experience. 

The use of Expo as a hybrid cross-platform development tool offers several benefits: reduced development overhead, widespread technology adoption, and the convenience of deploying to multiple platforms. 