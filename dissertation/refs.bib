
@article{chernev_choice_2015,
	title = {Choice overload: {A} conceptual review and meta-analysis},
	volume = {25},
	issn = {1532-7663},
	shorttitle = {Choice overload},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1016/j.jcps.2014.08.002},
	doi = {10.1016/j.jcps.2014.08.002},
	abstract = {Despite the voluminous evidence in support of the paradoxical finding that providing individuals with more options can be detrimental to choice, the question of whether and when large assortments impede choice remains open. Even though extant research has identified a variety of antecedents and consequences of choice overload, the findings of the individual studies fail to come together into a cohesive understanding of when large assortments can benefit choice and when they can be detrimental to choice. In a meta-analysis of 99 observations (N = 7202) reported by prior research, we identify four key factors—choice set complexity, decision task difficulty, preference uncertainty, and decision goal—that moderate the impact of assortment size on choice overload. We further show that each of these four factors has a reliable and significant impact on choice overload, whereby higher levels of decision task difficulty, greater choice set complexity, higher preference uncertainty, and a more prominent, effort-minimizing goal facilitate choice overload. We also find that four of the measures of choice overload used in prior research—satisfaction/confidence, regret, choice deferral, and switching likelihood—are equally powerful measures of choice overload and can be used interchangeably. Finally, we document that when moderating variables are taken into account the overall effect of assortment size on choice overload is significant—a finding counter to the data reported by prior meta-analytic research.},
	language = {en},
	number = {2},
	urldate = {2025-01-12},
	journal = {Journal of Consumer Psychology},
	author = {Chernev, Alexander and Böckenholt, Ulf and Goodman, Joseph},
	year = {2015},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1016/j.jcps.2014.08.002},
	keywords = {Assortment, Choice overload, Decision complexity, Meta-analysis},
	pages = {333--358},
	file = {Snapshot:/Users/vishal/Zotero/storage/8T5YB9QL/j.jcps.2014.08.html:text/html},
}

@article{korff_too_nodate,
	title = {Too {Much} {Choice}: {End}-{User} {Privacy} {Decisions} in the {Context} of {Choice} {Proliferation}},
	abstract = {Choice proliferation, a research stream in psychology, studies adverse eﬀects of human decision-making as the number of options to choose from increases. We test if these eﬀects can be elicited in a privacy context. Decision ﬁeld theory suggests two factors that potentially aﬀect end-users’ reﬂection of disclosure decisions: (1) choice amount, which we test by changing the number of checkboxes in a privacy settings dialog; and (2) choice structure, tested by varying the sensitivity of personal data items which are jointly controlled by each checkbox. We test both factors in a quantitative 2 × 2 between-subject experiment with stimuli calibrated in a pre-study with 60 respondents. In the main experiment, 112 German-speaking university students were asked to enter personal data into an ostensible business networking website and decide if and with whom it should be shared. Using an established item battery, we ﬁnd that participants who are confronted with a larger amount of privacy options subsequently report more negative feelings, experience more regret, and are less satisﬁed with the choices made. We observe a similar tendency, albeit weaker and statistically insigniﬁcant in our small sample, for the complexity of the choice structure if the number of options remains constant.},
	language = {en},
	author = {Korff, Stefan and Böhme, Rainer},
	file = {PDF:/Users/vishal/Zotero/storage/IKN9JE47/Korff and Böhme - Too Much Choice End-User Privacy Decisions in the Context of Choice Proliferation.pdf:application/pdf},
}

@misc{zhou_spoiled_2020,
	title = {Spoiled for {Choice}? {Personalized} {Recommendation} for {Healthcare} {Decisions}: {A} {Multi}-{Armed} {Bandit} {Approach}},
	shorttitle = {Spoiled for {Choice}?},
	url = {http://arxiv.org/abs/2009.06108},
	doi = {10.48550/arXiv.2009.06108},
	abstract = {Online healthcare communities provide users with various healthcare interventions to promote healthy behavior and improve adherence. When faced with too many intervention choices, however, individuals may find it difficult to decide which option to take, especially when they lack the experience or knowledge to evaluate different options. The choice overload issue may negatively affect users' engagement in health management. In this study, we take a design-science perspective to propose a recommendation framework that helps users to select healthcare interventions. Taking into account that users' health behaviors can be highly dynamic and diverse, we propose a multi-armed bandit (MAB)-driven recommendation framework, which enables us to adaptively learn users' preference variations while promoting recommendation diversity in the meantime. To better adapt an MAB to the healthcare context, we synthesize two innovative model components based on prominent health theories. The first component is a deep-learning-based feature engineering procedure, which is designed to learn crucial recommendation contexts in regard to users' sequential health histories, health-management experiences, preferences, and intrinsic attributes of healthcare interventions. The second component is a diversity constraint, which structurally diversifies recommendations in different dimensions to provide users with well-rounded support. We apply our approach to an online weight management context and evaluate it rigorously through a series of experiments. Our results demonstrate that each of the design components is effective and that our recommendation design outperforms a wide range of state-of-the-art recommendation systems. Our study contributes to the research on the application of business intelligence and has implications for multiple stakeholders, including online healthcare platforms, policymakers, and users.},
	urldate = {2025-01-12},
	publisher = {arXiv},
	author = {Zhou, Tongxin and Wang, Yingfei and Lu and Yan and Tan, Yong},
	month = sep,
	year = {2020},
	note = {arXiv:2009.06108 [cs]},
	keywords = {Computer Science - Information Retrieval, Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: 39 pages, 8 figures, 7 tables},
	file = {Full Text PDF:/Users/vishal/Zotero/storage/UFJDM28H/Zhou et al. - 2020 - Spoiled for Choice Personalized Recommendation for Healthcare Decisions A Multi-Armed Bandit Appro.pdf:application/pdf;Snapshot:/Users/vishal/Zotero/storage/BYITW5YB/2009.html:text/html},
}

@article{besedes_reducing_nodate,
	title = {Reducing {Choice} {Overload} without {Reducing} {Choices}},
	abstract = {Previous studies have demonstrated that a multitude of options can lead to choice overload, reducing decision quality. Through controlled experiments, we examine sequential choice architectures that enable the choice set to remain large while potentially reducing the effect of choice overload. A specific tournament-style architecture achieves this goal. An alternate architecture in which subjects compare each subset of options to the most preferred option encountered thus far fails to improve performance due to the status quo bias. Subject preferences over different choice architectures are negatively correlated with performance, suggesting that providing choice over architectures might reduce the quality of decisions.},
	language = {en},
	author = {Besedeš, Tibor and Deck, Cary and Sarangi, Sudipta and Shor, Mikhael},
	file = {PDF:/Users/vishal/Zotero/storage/QHE5RAL6/Besedeš et al. - Reducing Choice Overload without Reducing Choices.pdf:application/pdf},
}

@article{yang_role_nodate,
	title = {The {Role} of {Design} in {Creating} {Machine}-{Learning}-{Enhanced} {User} {Experience}},
	abstract = {Machine learning (ML) applications that directly interface with everyday users are now increasingly pervasive and powerful. However, user experience (UX) practitioners are lagging behind in leveraging this increasing common technology. ML is not yet a standard part of UX design practice, in either design patterns, prototyping tools, or education. This paper is a reflection on my experience designing MLmediated UX. I illustrate the role UX practice can play in making machine intelligence usable and valuable for everyday users: it can help identify 1) how to choose the right ML applications. 2) how to design the ML right. The separation of the two concerns is a first step to untangling the tight interplay between ML and UX. I highlight the unique challenges and the implications for future research directions.},
	language = {en},
	author = {Yang, Qian},
	file = {PDF:/Users/vishal/Zotero/storage/YGH7S5H4/Yang - The Role of Design in Creating Machine-Learning-Enhanced User Experience.pdf:application/pdf},
}

@article{abbas_user_2022,
	title = {User {Experience} {Design} {Using} {Machine} {Learning}: {A} {Systematic} {Review}},
	volume = {10},
	issn = {2169-3536},
	shorttitle = {User {Experience} {Design} {Using} {Machine} {Learning}},
	url = {https://ieeexplore.ieee.org/document/9770797/?arnumber=9770797},
	doi = {10.1109/ACCESS.2022.3173289},
	abstract = {User experience (UX) is the key to increased productivity by enhancing the usability and interactivity of the product. Machine learning (ML) solutions have raised user and academic awareness of technical innovation. As a result, ML is becoming increasingly popular to improve the quality of UX. Several investigations have highlighted a potential lack of studies on the overall challenges and recommendations for UX using ML. Therefore, more attention should be paid to ML’s existence and potential applications across various applications to get the most out of ML techniques to improve the UX design process. To this objective, a systematic review of the literature was performed as to determine the challenges faced by UX designers when incorporating ML in their design process. Recommendations that help UX designers incorporate ML into UX design will be highlighted. Furthermore, the PRISMA approach is used (a process that has been established in the literature), to restrict the chance of bias at the selection stage. Relevant articles in the following four databases were searched: IEEE Xplore, Scopus, Web of Science, and ACM. The findings revealed that the number of publications on issues linked to UX with ML had advanced exponentially. This review highlights the challenges, recommendations, tools, algorithms, techniques and datasets used in different studies. In addition, suggestions are given for future investigations.},
	urldate = {2025-01-21},
	journal = {IEEE Access},
	author = {Abbas, Abdallah M. H. and Ghauth, Khairil Imran and Ting, Choo-Yee},
	year = {2022},
	note = {Conference Name: IEEE Access},
	keywords = {Databases, ED, experience design, Graphical user interfaces, HCI, Libraries, machine learning, Machine learning, Metadata, ML, Systematics, user behavior, User experience, user interaction, UX, UX design},
	pages = {51501--51514},
	file = {Full Text PDF:/Users/vishal/Zotero/storage/NFY8VBRS/Abbas et al. - 2022 - User Experience Design Using Machine Learning A Systematic Review.pdf:application/pdf;IEEE Xplore Abstract Record:/Users/vishal/Zotero/storage/RRBCELR4/9770797.html:text/html},
}

@article{carmona_relationship_2018,
	title = {The {Relationship} {Between} {User} {Experience} and {Machine} {Learning}},
	issn = {1556-5068},
	url = {https://www.ssrn.com/abstract=3173932},
	doi = {10.2139/ssrn.3173932},
	abstract = {Based on our primary research question of what the relationship between user experience (UX) and machine learning (ML) is, this literature review examines how UX and ML function independently and interact with each other. We review literature with regard to the development of UX and ML separately, as well as the combination of these two areas. Our ultimate findings focus on four dimensions: the relationship between UX and ML, the advantages of integrating UX and ML, the challenges of applying ML technology to UX design, as well as the future implications in using ML to enhance UX. Finally, we give our suggestions concerning the establishment of a better ecosystem between UX and ML.},
	language = {en},
	urldate = {2025-01-21},
	journal = {SSRN Electronic Journal},
	author = {Carmona, Kim and Finley, Erin and Li, Meng},
	year = {2018},
	file = {PDF:/Users/vishal/Zotero/storage/QHJIB29V/Carmona et al. - 2018 - The Relationship Between User Experience and Machine Learning.pdf:application/pdf},
}

@misc{cristofaro_overview_2020,
	title = {An {Overview} of {Privacy} in {Machine} {Learning}},
	url = {http://arxiv.org/abs/2005.08679},
	doi = {10.48550/arXiv.2005.08679},
	abstract = {Over the past few years, providers such as Google, Microsoft, and Amazon have started to provide customers with access to software interfaces allowing them to easily embed machine learning tasks into their applications. Overall, organizations can now use Machine Learning as a Service (MLaaS) engines to outsource complex tasks, e.g., training classifiers, performing predictions, clustering, etc. They can also let others query models trained on their data. Naturally, this approach can also be used (and is often advocated) in other contexts, including government collaborations, citizen science projects, and business-to-business partnerships. However, if malicious users were able to recover data used to train these models, the resulting information leakage would create serious issues. Likewise, if the inner parameters of the model are considered proprietary information, then access to the model should not allow an adversary to learn such parameters. In this document, we set to review privacy challenges in this space, providing a systematic review of the relevant research literature, also exploring possible countermeasures. More specifically, we provide ample background information on relevant concepts around machine learning and privacy. Then, we discuss possible adversarial models and settings, cover a wide range of attacks that relate to private and/or sensitive information leakage, and review recent results attempting to defend against such attacks. Finally, we conclude with a list of open problems that require more work, including the need for better evaluations, more targeted defenses, and the study of the relation to policy and data protection efforts.},
	urldate = {2025-01-21},
	publisher = {arXiv},
	author = {Cristofaro, Emiliano De},
	month = may,
	year = {2020},
	note = {arXiv:2005.08679 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computers and Society, Computer Science - Cryptography and Security},
	file = {Full Text PDF:/Users/vishal/Zotero/storage/UUASDIRB/Cristofaro - 2020 - An Overview of Privacy in Machine Learning.pdf:application/pdf;Snapshot:/Users/vishal/Zotero/storage/WWZNE4WU/2005.html:text/html},
}

@misc{gitonga_real-time_2024,
	title = {Real-time {Web} with {Server} {Sent} {Events}},
	url = {https://medium.com/@maryanngitonga/real-time-web-with-server-sent-events-84a335ac1856},
	abstract = {If you have used ChatGPT, have you ever wondered how the bot effortlessly generates responses, emulating real-time texting? The secret lies…},
	language = {en},
	urldate = {2025-01-21},
	journal = {Medium},
	author = {Gitonga, Maryann},
	month = jan,
	year = {2024},
	file = {Snapshot:/Users/vishal/Zotero/storage/4UXRUMRU/real-time-web-with-server-sent-events-84a335ac1856.html:text/html},
}

@article{ganesan_machine_2022,
	title = {Machine {Learning} in {Mobile} {Applications}},
	volume = {11},
	issn = {2320088X},
	url = {https://ijcsmc.com/docs/papers/February2022/V11I2202217.pdf},
	doi = {10.47760/ijcsmc.2022.v11i02.013},
	abstract = {Machine learning is a branch of computer science that enables computers to learn without being explicitly programmed. One of the most exciting technologies that one has ever encountered is machine learning. As the name implies, it provides the computer with the ability to learn, which makes it more humanlike. Machine learning is now employed in a variety of applications, including self-driving cars, personal assistants such as Cortana, Alexa, and Siri, and security technologies such as face recognition. Developers of mobile applications are increasingly being pushed to include machine learning technology in their apps. This is unfamiliar territory for many of them. In this research paper, we will look at how machine learning relates to AI in this context, with an emphasis on application developers. This paper demonstrates different machine learning types, frameworks, and tools available on the market and how to use them to create the statistical models needed to use them in mobile applications without having to learn more about the complexity of algorithms and how they train and learn models. Also, this article covers the basic architectures that mobile applications can leverage to work with machine learning.},
	language = {en},
	number = {2},
	urldate = {2025-01-21},
	journal = {International Journal of Computer Science and Mobile Computing},
	author = {Ganesan, Veeramani},
	month = feb,
	year = {2022},
	pages = {110--118},
	file = {PDF:/Users/vishal/Zotero/storage/ZSLHFFMB/Ganesan - 2022 - Machine Learning in Mobile Applications.pdf:application/pdf},
}

@article{ray_review_2022,
	title = {A review on {TinyML}: {State}-of-the-art and prospects},
	volume = {34},
	issn = {13191578},
	shorttitle = {A review on {TinyML}},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1319157821003335},
	doi = {10.1016/j.jksuci.2021.11.019},
	abstract = {Machine learning has become an indispensable part of the existing technological domain. Edge computing and Internet of Things (IoT) together presents a new opportunity to imply machine learning techniques at the resource constrained embedded devices at the edge of the network. Conventional machine learning requires enormous amount of power to predict a scenario. Embedded machine learning – TinyML paradigm aims to shift such plethora from traditional high-end systems to low-end clients. Several challenges are paved while doing such transition such as, maintaining the accuracy of learning models, provide train-to-deploy facility in resource frugal tiny edge devices, optimizing processing capacity, and improving reliability. In this paper, we present an intuitive review about such possibilities for TinyML. We ﬁrstly, present background of TinyML. Secondly, we list the tool sets for supporting TinyML. Thirdly, we present key enablers for improvement of TinyML systems. Fourthly, we present state-of-the-art about frameworks for TinyML. Finally, we identify key challenges and prescribe a future roadmap for mitigating several research issues of TinyML.},
	language = {en},
	number = {4},
	urldate = {2025-01-21},
	journal = {Journal of King Saud University - Computer and Information Sciences},
	author = {Ray, Partha Pratim},
	month = apr,
	year = {2022},
	pages = {1595--1623},
	file = {PDF:/Users/vishal/Zotero/storage/FE8YHFHL/Ray - 2022 - A review on TinyML State-of-the-art and prospects.pdf:application/pdf},
}

@article{schizas_tinyml_2022,
	title = {{TinyML} for {Ultra}-{Low} {Power} {AI} and {Large} {Scale} {IoT} {Deployments}: {A} {Systematic} {Review}},
	volume = {14},
	copyright = {https://creativecommons.org/licenses/by/4.0/},
	issn = {1999-5903},
	shorttitle = {{TinyML} for {Ultra}-{Low} {Power} {AI} and {Large} {Scale} {IoT} {Deployments}},
	url = {https://www.mdpi.com/1999-5903/14/12/363},
	doi = {10.3390/fi14120363},
	abstract = {The rapid emergence of low-power embedded devices and modern machine learning (ML) algorithms has created a new Internet of Things (IoT) era where lightweight ML frameworks such as TinyML have created new opportunities for ML algorithms running within edge devices. In particular, the TinyML framework in such devices aims to deliver reduced latency, efficient bandwidth consumption, improved data security, increased privacy, lower costs and overall network cost reduction in cloud environments. Its ability to enable IoT devices to work effectively without constant connectivity to cloud services, while nevertheless providing accurate ML services, offers a viable alternative for IoT applications seeking cost-effective solutions. TinyML intends to deliver on-premises analytics that bring significant value to IoT services, particularly in environments with limited connection. This review article defines TinyML, presents an overview of its benefits and uses and provides background information based on up-to-date literature. Then, we demonstrate the TensorFlow Lite framework which supports TinyML along with analytical steps for an ML model creation. In addition, we explore the integration of TinyML with network technologies such as 5G and LPWAN. Ultimately, we anticipate that this analysis will serve as an informational pillar for the IoT/Cloud research community and pave the way for future studies.},
	language = {en},
	number = {12},
	urldate = {2025-01-21},
	journal = {Future Internet},
	author = {Schizas, Nikolaos and Karras, Aristeidis and Karras, Christos and Sioutas, Spyros},
	month = dec,
	year = {2022},
	pages = {363},
	file = {PDF:/Users/vishal/Zotero/storage/JF6IEKYE/Schizas et al. - 2022 - TinyML for Ultra-Low Power AI and Large Scale IoT Deployments A Systematic Review.pdf:application/pdf},
}

@article{tsoukas_review_2024,
	title = {A {Review} on the emerging technology of {TinyML}},
	volume = {56},
	issn = {0360-0300, 1557-7341},
	url = {https://dl.acm.org/doi/10.1145/3661820},
	doi = {10.1145/3661820},
	abstract = {Tiny Machine Learning (TinyML) is an emerging technology proposed by the scientific community for developing autonomous and secure devices that can gather, process, and provide results without transferring data to external entities. The technology aims to democratize AI by making it available to more sectors and contribute to the digital revolution of intelligent devices. In this work, a classification of the most common optimization techniques for Neural Network compression is conducted. Additionally, a review of the development boards and TinyML software is presented. Furthermore, the work provides educational resources, a classification of the technology applications, and future directions and concludes with the challenges and considerations.},
	language = {en},
	number = {10},
	urldate = {2025-01-21},
	journal = {ACM Computing Surveys},
	author = {Tsoukas, Vasileios and Gkogkidis, Anargyros and Boumpa, Eleni and Kakarountas, Athanasios},
	month = oct,
	year = {2024},
	pages = {1--37},
	file = {Full Text PDF:/Users/vishal/Zotero/storage/2EWLHISX/Tsoukas et al. - 2024 - A Review on the emerging technology of TinyML.pdf:application/pdf},
}

@inproceedings{haseeb_optimizing_2024,
	title = {Optimizing {Machine} {Learning} for {ResourceConstrained} {Devices}: {A} {Comparative} {Analysis} of {Preprocessing} {Techniques} and {Machine} {Learning} {Algorithms}},
	shorttitle = {Optimizing {Machine} {Learning} for {ResourceConstrained} {Devices}},
	url = {https://ieeexplore.ieee.org/document/10603066/?arnumber=10603066},
	doi = {10.1109/ISSC61953.2024.10603066},
	abstract = {One of the challenges in the rapid development of Internet of Things (IoT) and edge computing is deploying machine learning (ML) models on resource constrained devices (RCD). Preprocessing methods are important for improving ML model performance, especially when limited computing power is involved. This research examines the effectiveness of four prominent preprocessing methods in conjunction with four common ML algorithms: Support Vector Machines (SVM), Random Forest (RF), Logistic Regression (LR), and K-Nearest Neighbours (KNN). The methods include quantisation, Min-Max scaling, standardisation (Z-score normalisation), and quantile transformation. We aim to examine how different preprocessing techniques affect the performance of various ML algorithms. By doing so, we offer valuable insights into the most effective preprocessing approach for different algorithms and HAR dataset. The results of our experiments show that different combinations of preprocessing methods and ML algorithms can achieve different levels of accuracy, f1 score and training time. Remarkably, quantisation which, is frequently used to minimise the memory footprint of models produced, average results for all techniques i.e. 58\%. On the other hand, Min-Max scaling performed better with RF, attaining 94.72\% accuracy with a training time of 6.4013 sec, indicating that it can be used in situations where resources are limited. One widespread normalisation method, standardisation, performed well with both RF and SVM, achieving accuracy of 94.56\% and 48.66\%, respectively. Furthermore, quantile transformation provides promising outcomes with accuracies ranging from 69.51\% to 94.68\% for all techniques. These results highlight the importance of modifying the discussed four preprocessing methods according to specific ML algorithms, applications, and available RCD such as limited processer resources and limited memory. These results are helpful to researchers who are working to achieve higher model performance in the context of RCD.},
	urldate = {2025-01-21},
	booktitle = {2024 35th {Irish} {Signals} and {Systems} {Conference} ({ISSC})},
	author = {Haseeb, Abdul and Cleland, Ian and Nugent, Chris and McLaughlin, James},
	month = jun,
	year = {2024},
	note = {ISSN: 2688-1454},
	keywords = {Accuracy, Machine Learning, Machine learning algorithms, Min-Max, Performance evaluation, Preprocessing, Quantile Transformer, Quantisation, Quantization (signal), Radio frequency, Resource Constrained Devices, Standardization (Z-score), Support vector machines, Training},
	pages = {1--5},
	file = {IEEE Xplore Abstract Record:/Users/vishal/Zotero/storage/HB5T8Y8W/10603066.html:text/html},
}

@article{mishra_lirad_2025,
	title = {{LIRAD}: lightweight tree-based approaches on resource constrained {IoT} devices for attack detection},
	volume = {28},
	issn = {1386-7857, 1573-7543},
	shorttitle = {{LIRAD}},
	url = {https://link.springer.com/10.1007/s10586-024-04792-x},
	doi = {10.1007/s10586-024-04792-x},
	abstract = {The surge in Internet of Things usage has raised security breaches within the IoT ecosystem. Consequently, there is a pressing need to deploy robust Intrusion Detection Systems (IDSs) to safeguard IoT environments. This paper proposes a framework designed to establish stringent decision boundaries for effective attack detection, leveraging two prevalent datasets: CICIDS2017 and EDGE-IIOT. These datasets exhibit imbalanced class distributions and encompass numerous features with distinct characteristics. To address the class imbalance, the framework employs sampling techniques such as the synthetic minority oversampling technique with a genetic algorithm (GA-SMOTE) and with particle swarm optimization (SMOTE-PSO) along with random undersampling (RUS). The proposed framework utilizes tree-based learning algorithms, Decision Tree, Random Forest, and XGBoost, to identify cyberattacks and associated anomalies within the constrained IoT landscape. Feature selection is performed using the Boruta and WOA algorithms, and pruning algorithms are used to optimize the complexity of the model. The efﬁcacy of the framework is evaluated using standard metrics on both workstations and Raspberry Pi boards to demonstrate its effectiveness on constrained IoT devices. The evaluation results demonstrate that the proposed model achieves a remarkable accuracy of 99.99\% in identifying cyberattacks and related anomalies, exceeding the performance of existing baseline models in the CICIDS2017 dataset. It also obtains a high accuracy of 99.5\% on EDGE-IIOT dataset. Furthermore, the framework shows promising results in terms of memory usage and execution time, achieving the best performance of 3.07 MB of memory usage and 4.26 s of execution time for the CICIDS2017 dataset and 1.93 MB of memory usage and 4.09 s of execution time for the EDGE-IIOT dataset when implemented on Raspberry Pi boards.},
	language = {en},
	number = {2},
	urldate = {2025-01-21},
	journal = {Cluster Computing},
	author = {Mishra, Sanket and Anithakumari, Thangellamudi and Sahay, Rashmi and Shrivastava, Rajesh Kumar and Mohanty, Sachi Nandan and Shahid, Afzal Hussain},
	month = apr,
	year = {2025},
	pages = {140},
	file = {PDF:/Users/vishal/Zotero/storage/F4IDFY3A/Mishra et al. - 2025 - LIRAD lightweight tree-based approaches on resource constrained IoT devices for attack detection.pdf:application/pdf},
}

@incollection{schwartz_paradox_2015,
	title = {The {Paradox} of {Choice}},
	copyright = {Copyright © 2015 John Wiley \& Sons, Inc},
	isbn = {978-1-118-99687-4},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/9781118996874.ch8},
	abstract = {Choice is what enables each person to pursue precisely those objects and activities that best satisfy his or her own preferences within the limits of his or her resources. This chapter argues that choice, and with it freedom, autonomy, and self-determination, can become excessive, and that when that happens, freedom can be experienced as a kind of misery-inducing tyranny. Though one cannot be free without choice, it is arguable that choice-induced paralysis is a sign of diminished rather than enhanced freedom. Though policy initiatives can operate to minimize the negative effects of choice overload, they contain the danger that they will simultaneously undermine the positive effects of freedom of choice. The reason people can say anything and be understood is that they cannot say anything in any way they want. It is linguistic constraint, in the form of these rules, that makes linguistic freedom possible.},
	language = {en},
	urldate = {2025-04-21},
	booktitle = {Positive {Psychology} in {Practice}},
	publisher = {John Wiley \& Sons, Ltd},
	author = {Schwartz, Barry},
	year = {2015},
	doi = {10.1002/9781118996874.ch8},
	note = {Section: 8
\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781118996874.ch8},
	keywords = {choice-induced paralysis, diminished freedom, enhanced freedom, freedom of choice, linguistic freedom, misery-inducing tyranny},
	pages = {121--138},
	file = {Snapshot:/Users/vishal/Zotero/storage/FL36DQ2X/9781118996874.html:text/html},
}

@inproceedings{kamath_comparative_2018,
	address = {Halifax NS Canada},
	title = {Comparative {Study} between {Traditional} {Machine} {Learning} and {Deep} {Learning} {Approaches} for {Text} {Classification}},
	isbn = {978-1-4503-5769-2},
	url = {https://dl.acm.org/doi/10.1145/3209280.3209526},
	doi = {10.1145/3209280.3209526},
	language = {en},
	urldate = {2025-04-21},
	booktitle = {Proceedings of the {ACM} {Symposium} on {Document} {Engineering} 2018},
	publisher = {ACM},
	author = {Kamath, Cannannore Nidhi and Bukhari, Syed Saqib and Dengel, Andreas},
	month = aug,
	year = {2018},
	pages = {1--11},
}

@article{taye_understanding_2023,
	title = {Understanding of {Machine} {Learning} with {Deep} {Learning}: {Architectures}, {Workflow}, {Applications} and {Future} {Directions}},
	volume = {12},
	copyright = {https://creativecommons.org/licenses/by/4.0/},
	issn = {2073-431X},
	shorttitle = {Understanding of {Machine} {Learning} with {Deep} {Learning}},
	url = {https://www.mdpi.com/2073-431X/12/5/91},
	doi = {10.3390/computers12050091},
	abstract = {In recent years, deep learning (DL) has been the most popular computational approach in the ﬁeld of machine learning (ML), achieving exceptional results on a variety of complex cognitive tasks, matching or even surpassing human performance. Deep learning technology, which grew out of artiﬁcial neural networks (ANN), has become a big deal in computing because it can learn from data. The ability to learn enormous volumes of data is one of the beneﬁts of deep learning. In the past few years, the ﬁeld of deep learning has grown quickly, and it has been used successfully in a wide range of traditional ﬁelds. In numerous disciplines, including cybersecurity, natural language processing, bioinformatics, robotics and control, and medical information processing, deep learning has outperformed well-known machine learning approaches. In order to provide a more ideal starting point from which to create a comprehensive understanding of deep learning, also, this article aims to provide a more detailed overview of the most signiﬁcant facets of deep learning, including the most current developments in the ﬁeld. Moreover, this paper discusses the signiﬁcance of deep learning and the various deep learning techniques and networks. Additionally, it provides an overview of real-world application areas where deep learning techniques can be utilised. We conclude by identifying possible characteristics for future generations of deep learning modelling and providing research suggestions. On the same hand, this article intends to provide a comprehensive overview of deep learning modelling that can serve as a resource for academics and industry people alike. Lastly, we provide additional issues and recommended solutions to assist researchers in comprehending the existing research gaps. Various approaches, deep learning architectures, strategies, and applications are discussed in this work.},
	language = {en},
	number = {5},
	urldate = {2025-04-21},
	journal = {Computers},
	author = {Taye, Mohammad Mustafa},
	month = apr,
	year = {2023},
	pages = {91},
	file = {PDF:/Users/vishal/Zotero/storage/3K68IHHX/Taye - 2023 - Understanding of Machine Learning with Deep Learning Architectures, Workflow, Applications and Futu.pdf:application/pdf},
}

@article{gardazi_bert_2025,
	title = {{BERT} applications in natural language processing: a review},
	volume = {58},
	issn = {1573-7462},
	shorttitle = {{BERT} applications in natural language processing},
	url = {https://link.springer.com/10.1007/s10462-025-11162-5},
	doi = {10.1007/s10462-025-11162-5},
	abstract = {BERT (Bidirectional Encoder Representations from Transformers) has revolutionized Natural Language Processing (NLP) by significantly enhancing the capabilities of language models. This review study examines the complex nature of BERT, including its structure, utilization in different NLP tasks, and the further development of its design via modifications. The study thoroughly analyses the methodological aspects, conducting a comprehensive analysis of the planning process, the implemented procedures, and the criteria used to decide which data to include or exclude in the evaluation framework. In addition, the study thoroughly examines the influence of BERT on several NLP tasks, such as Sentence Boundary Detection, Tokenization, Grammatical Error Detection and Correction, Dependency Parsing, Named Entity Recognition, Part of Speech Tagging, Question Answering Systems, Machine Translation, Sentiment analysis, fake review detection and Cross-lingual transfer learning. The review study adds to the current literature by integrating ideas from multiple sources, explicitly emphasizing the problems and prospects in BERT-based models. The objective is to comprehensively comprehend BERT and its implementations, targeting both experienced researchers and novices in the domain of NLP. Consequently, the present study is expected to inspire more research endeavors, promote innovative adaptations of BERT, and deepen comprehension of its extensive capabilities in various NLP applications. The results presented in this research are anticipated to influence the advancement of future language models and add to the ongoing discourse on enhancing technology for understanding natural language.},
	language = {en},
	number = {6},
	urldate = {2025-04-21},
	journal = {Artificial Intelligence Review},
	author = {Gardazi, Nadia Mushtaq and Daud, Ali and Malik, Muhammad Kamran and Bukhari, Amal and Alsahfi, Tariq and Alshemaimri, Bader},
	month = mar,
	year = {2025},
	pages = {166},
	file = {PDF:/Users/vishal/Zotero/storage/7W4ZMAGL/Gardazi et al. - 2025 - BERT applications in natural language processing a review.pdf:application/pdf},
}

@misc{devlin_bert_2019,
	title = {{BERT}: {Pre}-training of {Deep} {Bidirectional} {Transformers} for {Language} {Understanding}},
	shorttitle = {{BERT}},
	url = {http://arxiv.org/abs/1810.04805},
	doi = {10.48550/arXiv.1810.04805},
	abstract = {We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models, BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5\% (7.7\% point absolute improvement), MultiNLI accuracy to 86.7\% (4.6\% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).},
	urldate = {2025-04-21},
	publisher = {arXiv},
	author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
	month = may,
	year = {2019},
	note = {arXiv:1810.04805 [cs]},
	keywords = {Computer Science - Computation and Language},
	file = {Full Text PDF:/Users/vishal/Zotero/storage/QW5TIVKS/Devlin et al. - 2019 - BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.pdf:application/pdf;Snapshot:/Users/vishal/Zotero/storage/ZW8SUTVS/1810.html:text/html},
}

@misc{sanh_distilbert_2020,
	title = {{DistilBERT}, a distilled version of {BERT}: smaller, faster, cheaper and lighter},
	shorttitle = {{DistilBERT}, a distilled version of {BERT}},
	url = {http://arxiv.org/abs/1910.01108},
	doi = {10.48550/arXiv.1910.01108},
	abstract = {As Transfer Learning from large-scale pre-trained models becomes more prevalent in Natural Language Processing (NLP), operating these large models in on-the-edge and/or under constrained computational training or inference budgets remains challenging. In this work, we propose a method to pre-train a smaller general-purpose language representation model, called DistilBERT, which can then be fine-tuned with good performances on a wide range of tasks like its larger counterparts. While most prior work investigated the use of distillation for building task-specific models, we leverage knowledge distillation during the pre-training phase and show that it is possible to reduce the size of a BERT model by 40\%, while retaining 97\% of its language understanding capabilities and being 60\% faster. To leverage the inductive biases learned by larger models during pre-training, we introduce a triple loss combining language modeling, distillation and cosine-distance losses. Our smaller, faster and lighter model is cheaper to pre-train and we demonstrate its capabilities for on-device computations in a proof-of-concept experiment and a comparative on-device study.},
	urldate = {2025-04-21},
	publisher = {arXiv},
	author = {Sanh, Victor and Debut, Lysandre and Chaumond, Julien and Wolf, Thomas},
	month = mar,
	year = {2020},
	note = {arXiv:1910.01108 [cs]},
	keywords = {Computer Science - Computation and Language},
	annote = {Comment: February 2020 - Revision: fix bug in evaluation metrics, updated metrics, argumentation unchanged. 5 pages, 1 figure, 4 tables. Accepted at the 5th Workshop on Energy Efficient Machine Learning and Cognitive Computing - NeurIPS 2019},
	file = {Full Text PDF:/Users/vishal/Zotero/storage/LTQPPSC9/Sanh et al. - 2020 - DistilBERT, a distilled version of BERT smaller, faster, cheaper and lighter.pdf:application/pdf;Snapshot:/Users/vishal/Zotero/storage/Y8E5YLCZ/1910.html:text/html},
}

@inproceedings{xanthopoulos_comparative_2013,
	address = {Thessaloniki Greece},
	title = {A comparative analysis of cross-platform development approaches for mobile applications},
	isbn = {978-1-4503-1851-8},
	url = {https://dl.acm.org/doi/10.1145/2490257.2490292},
	doi = {10.1145/2490257.2490292},
	abstract = {Nowadays, native mobile applications (mobile apps) are targeted at specific mobile platforms. This phenomenon imposes severe constraints, such as the use of different development environments, technologies, and APIs (Application Programming Interfaces) for each mobile platform, leading inevitably to a waste of development time and effort, and an increased maintenance cost.},
	language = {en},
	urldate = {2025-04-21},
	booktitle = {Proceedings of the 6th {Balkan} {Conference} in {Informatics}},
	publisher = {ACM},
	author = {Xanthopoulos, Spyros and Xinogalos, Stelios},
	month = sep,
	year = {2013},
	pages = {213--220},
	file = {PDF:/Users/vishal/Zotero/storage/SBZW8YNH/Xanthopoulos and Xinogalos - 2013 - A comparative analysis of cross-platform development approaches for mobile applications.pdf:application/pdf},
}

@misc{noauthor_expo_nodate,
	title = {Expo},
	url = {https://expo.dev/},
	abstract = {Expo is an open-source platform for making universal native apps for Android, iOS, and the web with JavaScript and React.},
	language = {en},
	urldate = {2025-04-21},
	journal = {Expo},
	file = {Snapshot:/Users/vishal/Zotero/storage/6SRLPCJU/expo.dev.html:text/html},
}

@misc{oh_what_2012,
	title = {What {Is} {CUDA}?},
	url = {https://blogs.nvidia.com/blog/what-is-cuda-2/},
	abstract = {What Is CUDA? CUDA is a parallel computing platform and programming model that makes using a GPU for general purpose computing simple.},
	language = {en-US},
	urldate = {2025-04-22},
	journal = {NVIDIA Blog},
	author = {Oh, Fred},
	month = sep,
	year = {2012},
	file = {Snapshot:/Users/vishal/Zotero/storage/2E74V9MJ/what-is-cuda-2.html:text/html},
}

@article{srinath_python_nodate,
	title = {Python – {The} {Fastest} {Growing} {Programming} {Language}},
	volume = {04},
	abstract = {Python is a suitable language for both learning and real world programming. Python is a powerful highlevel, object-oriented programming language created by Guido van Rossum. In this paper we first introduce you to the python programming characteristics and features. This paper also discusses about the reasons behind python being credited as the most fastest growing programming language in the recent times supported by research done over the articles procured from various magazines and popular websites. This paper features about the characteristics and most important features of python language, the types of programming supported by python and its users and its applications.},
	language = {en},
	number = {12},
	author = {Srinath, K R},
	file = {PDF:/Users/vishal/Zotero/storage/B5S3KWIM/Srinath - Python – The Fastest Growing Programming Language.pdf:application/pdf},
}

@misc{scarlett_why_2023,
	title = {Why {Python} keeps growing, explained},
	url = {https://github.blog/developer-skills/programming-languages-and-frameworks/why-python-keeps-growing-explained/},
	abstract = {A deep dive into why more people are using Python than ever, its key use cases, and why it’s still so popular 30-plus years after it was first released.},
	language = {en-US},
	urldate = {2025-04-22},
	journal = {The GitHub Blog},
	author = {Scarlett, Rizel},
	month = mar,
	year = {2023},
	file = {Snapshot:/Users/vishal/Zotero/storage/DAXYZAIA/why-python-keeps-growing-explained.html:text/html},
}

@misc{noauthor_top_nodate,
	title = {The top programming languages},
	url = {https://octoverse.github.com/2022/top-programming-languages},
	abstract = {Explore the top programming languages on GitHub—and what languages are growing the fastest.},
	language = {en-gb},
	urldate = {2025-04-22},
	journal = {The State of the Octoverse},
	file = {Snapshot:/Users/vishal/Zotero/storage/IBY7LBZU/top-programming-languages.html:text/html},
}

@misc{noauthor_top_nodate-1,
	title = {Top 6 {Benefits} of {Implementing} {TypeScript}},
	url = {https://strapi.io/blog/benefits-of-typescript#},
	abstract = {Find out what are some of the most immediate and most impactful benefits of implementing TypeScript in your projects.},
	language = {en},
	urldate = {2025-04-22},
	file = {Snapshot:/Users/vishal/Zotero/storage/375AQA9Q/benefits-of-typescript.html:text/html},
}

@misc{crudu_beyond_2024,
	title = {Beyond {Web} {Development} {Exploring} {Typescript} in {Mobile} {Applications}},
	url = {https://moldstud.com/articles/p-beyond-web-development-exploring-typescript-in-mobile-applications},
	abstract = {In the ever-evolving landscape of software development, TypeScript has emerged as a powerful tool for building robust and scalable web applications. But did you know that TypeScript can also be effectively used in mobile application development? In this article, we will explore the benefits of integrating TypeScript into mobile development and how it can enhance the development process.},
	language = {en},
	urldate = {2025-04-22},
	author = {Crudu, Valeriu},
	month = oct,
	year = {2024},
	note = {Section: Typescript developers questions},
	file = {Snapshot:/Users/vishal/Zotero/storage/ZAKJG8Z7/p-beyond-web-development-exploring-typescript-in-mobile-applications.html:text/html},
}

@article{sekhar_emmanni_role_2021,
	title = {The {Role} of {TypeScript} in {Enhancing} {Development} with {Modern} {JavaScript} {Frameworks}},
	volume = {10},
	issn = {23197064},
	url = {https://www.ijsr.net/getabstract.php?paperid=SR24401234212},
	doi = {10.21275/SR24401234212},
	abstract = {TypeScript has emerged as a key player in enhancing the robustness and maintainability of applications developed with modern JavaScript frameworks such as React, Angular, and Vue. This scholarly article delves into the transformative role of TypeScript by examining its integration within these frameworks, highlighting the myriad benefits it brings to the development process. Through empirical analysis, case studies, and developer testimonials, we explore how TypeScript’s static typing system significantly reduces runtime errors, thereby enhancing code quality and reliability. The study further investigates TypeScript's impact on developer productivity, facilitated by improved tooling support that accelerates the development cycle and simplifies project maintenance, especially in large-scale applications. By offering a comparative analysis of projects before and after adopting TypeScript, the article illustrates the tangible improvements in error detection, code maintainability, and collaboration among development teams. This comprehensive review underscores TypeScript’s indispensability in modern web development, positioning it as a critical tool for developers seeking to build scalable, high-quality web applications with the latest JavaScript frameworks. Through this exploration, the article aims to contribute to the broader understanding of TypeScript’s role in elevating the standards of web development practices today.},
	language = {en},
	number = {2},
	urldate = {2025-04-22},
	journal = {International Journal of Science and Research (IJSR)},
	author = {Sekhar Emmanni, Phani},
	month = feb,
	year = {2021},
	pages = {1738--1741},
	file = {PDF:/Users/vishal/Zotero/storage/AFLTA3QG/Sekhar Emmanni - 2021 - The Role of TypeScript in Enhancing Development with Modern JavaScript Frameworks.pdf:application/pdf},
}
